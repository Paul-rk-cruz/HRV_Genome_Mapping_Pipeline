    nextflow run /Users/Kurtisc/Downloads/CURRENT/Virus_Genome_Mapping_Pipeline/Virus_Genome_Mapping_Pipeline/main.nf --reads '/Users/Kurtisc/Downloads/CURRENT/test_fastq_se/' --outdir '/Users/Kurtisc/Downloads/CURRENT/test_output/' --singleEnd singleEnd
    
    
bedtools bamtobed -i V338470961_S2_L002_R1_001.bam | head -1
    
    
(base) Kurtisc@uwvirologys-iMac bam files % bedtools bamtobed -i V338470961_S2_L002_R1_001.bam | head -1 2> most_mapped.txt

JQ837720 Human rhinovirus C strain HRV-C17_p1192_sR2967_2009 polyprotein gene, complete cds	5265	5365	A01152:34:H25M7DRXY:2:2101:9335:4476 1:N:0:CGAGGCCAAG	27
command | cut -c1-8
    
    RHV__SAMPLE_REF_MAPPED=bedtools bamtobed -i V338470961_S2_L002_R1_001.bam | head -1 > most_mapped.text
    samtools faidx rhv_ref_db01.fasta ${RHV__SAMPLE_REF_MAPPED} > most_mapped.text
    
    bedtools bamtobed -i V338470881_S9_L001_R1_001.bam | head -1 > most_mapped.text
    
    
    
    #!/bin/bash
    // USE UNSORTED BAM FILE TO READ REF GENOME OF MOST MAPPED READS THEN SAVE INFO TO TEXT FILE
    bedtools bamtobed -i V338470881_S9_L001_R1_001.bam | head -1 > most_mapped.text
    // READ ACCESSION NUMBER FROM TEXT FILE
    REF_ACCESSION_NUM=head -c 8 <most_mapped.text>
    // USE SAM TOOLS TO EXTRACT GENOME REFERENCE FROM MULTI-FASTA - SAVE TO NEW FASTA FOR LATER USE
    samtools faidx rhv_ref_db01.fasta ${REF_ACCESSION_NUM} > MAPPED-REF-GENOME.fasta
    
    
    
    
    RHV__SAMPLE_REF_MAPPED=bedtools bamtobed -i ${base}.sorted.bam | head -1 | command | cut -c1-8
    RHV_SAMPLE_REF_FASTA=samtools faidx rhv_ref_db01.fasta ${RHV__SAMPLE_REF_MAPPED}
    
Just today I wrote a script to do exactly this using Biopython. I also add a warning If any the headers I wanted to filter was not present in the original fasta. So the python script filter_fasta_by_list_of_headers.py is :

#!/usr/bin/env python3

from Bio import SeqIO
import sys

ffile = SeqIO.parse(sys.argv[1], "fasta")
header_set = set(line.strip() for line in open(sys.argv[2]))

for seq_record in ffile:
    try:
        header_set.remove(seq_record.name)
    except KeyError:
        print(seq_record.format("fasta"))
        continue
if len(header_set) != 0:
    print(len(header_set),'of the headers from list were not identified in the input fasta file.', file=sys.stderr)
and usage :


filter_fasta_by_list_of_headers.py input.fasta list_of_scf_to_filter > filtered.fasta

P.S. it's quite easy to turn over the script to extract the sequences from the list (just the print line would have to move after line header_set.remove(seq_record.name)



1

This is what samtools faidx is intended for.

It needs to be called twice.

First, to create a FASTA index (*.fai file):

samtools faidx input.fasta
Secondly, to filter the FASTA file with the help of the index:

samtools faidx -o output.fasta input.fasta ids…
ids… are the IDs to retain, as individual arguments separated by space. If you’ve got a file blocklist.txt with IDs you want to discard (one per line), you first need to invert this, after having created the index (using Bash syntax):1

remove_ids=($(awk '{print $1}' input.fasta.fai | grep -v -f blocklist.txt))
… and then we can invoke the command as

samtools faidx -o output.fasta input.fasta "${remove_ids[@]}"
What’s nice about samtools faidx is that it also works with BGZF-compressed FASTA data — i.e. fa.gz files (but only if they were compressed using bgzip, which ships with Samtools, and the index must be generated on the compressed file). However, it will always write FASTA. If you want gzipped FASTA output, you need to manually stream the result into bgzip:


samtools faidx input.fasta.gz "${remove_ids[@]}" | bgzip -c >output.fasta.gz




    RHV__SAMPLE_REF_MAPPED= 
    RHV_SAMPLE_REF_FASTA=samtools faidx rhv_ref_db01.fasta ${mapped_ref}
    
**The below command outputs the reference sequence in fasta format
samtools faidx rhv_ref_db01.fasta FJ445111 Human rhinovirus 1 strain ATCC VR-1559, complete genome

  
  
   
  
  SELECT BASED ON QUALITY
samtools view -h -b -q 20 V338470961_S2_L002_R1_001.bam > V338470961_S2_L002_R1_001_Q.bam




samtools view -S -b V338470961_S2_L002_R1_001.sam > V338470961_S2_L002_R1_001.bam
samtools index V338470961_S2_L002_R1_001.bam
samtools view -H V338470961_S2_L002_R1_001.bam > V338470961_S2_L002_R1_001_header.txt
cat V338470961_S2_L002_R1_001_header.txt V338470961_S2_L002_R1_001.bam > V338470961_S2_L002_R1_001_subset_WithHeader.sam
samtools view -Sb V338470961_S2_L002_R1_001_subset_WithHeader.sam > V338470961_S2.bam

  
  samtools view V338470961_S2_L002_R1_001.bam | cut -f1,3
  
  

  

samtools view V338470961_S2_L002_R1_001.sorted.bam | cut -f 1 | head
samtools view -F 0x4 V338470961_S2_L002_R1_001.sorted.bam | cut -f 1 | head
samtools view -c -F 0x4 V338470961_S2_L002_R1_001.sorted.bam


samtools view V338470961_S2_L002_R1_001.sorted.bam | head -n 1
samtools view V338470961_S2_L002_R1_001.sorted.bam | head -n 5

head -100000 V338470881_S9_L001_R1_001.sorted.bam | awk 'BEGIN {FS="\t"} {print $3"\t"$4}' | sort | uniq -c | sort -n -r | head

head -10000 V338470881_S9_L001_R1_001.sorted.bam | awk 'BEGIN {FS="\t"} {print $3"\t"int($4/1000)}' | sort | uniq -c | sort -n -r | head

samtools view -H V338470881_S9_L001_R1_001.sorted.bam | grep '^@SQ'

samtools idxstats V338470881_S9_L001_R1_001.sorted.bam | awk '$4 != 0' | head -n-1 | wc -l

samtools view V338470881_S9_L001_R1_001.sorted.bam | wc -l

samtools view -f 0x2 V338470881_S9_L001_R1_001.sorted.bam | wc -l

bedtools getfasta [OPTIONS] -fi <input FASTA> -bed <BED/GFF/VCF>

Extract aligned reads from sorted bam file

samtools fasta V338470881_S9_L001_R1_001.sorted.bam -F 4 > V338470881_S9_L001_R1_001.fasta

samtools view -S -b V338470961_S2_L002_R1_001.sam V338470961_S2_L002_R1_001.bam
samtools view -bS V338470961_S2_L002_R1_001.sam | samtools sort - -o V338470961_S2_L002_R1_001.bam


The quick way to get the number of alignments on each reference is

samtools idxstats my_bam.bam
Number of reads on each reference is column 3. Although, as has been pointed out, this will give you the total number of alignments per reference, not the total number of reads (each read might give rise to more than one alignment). That said I do tend to us this as generally I'm after a rough approximation, rather than an accurate number.

In theory, only one alignment for each read should be marked as primary, so the following should give you what you need quickly and at low memory usage:

samtools view -bF 2304 V338470961_S2_L002_R1_001.bam > primary_only.bam
samtools index primary_only.bam
samtools idxstats primary_only.bam
samtools mpileup -uf rhv_ref_db01.fasta primary_only.bam | bcftools call -c | vcfutils.pl vcf2fq > done.bam
seqtk seq -aQ64 -q20 -n N done.bam > SAMPLE_cns.fasta




samtools
#index the bam file first
samtools index SAMPLE.bam
samtools view SAMPLE.bam
samtools view -b SAMPLE.bam

To extract ONLY aligned reads from a bam file:

samtools bam2fastq -o SAMPLE.fastq --no-unaligned SAMPLE.bam.bai

Fastest way to count number of reads

count
#number of reads
samtools idxstats SAMPLE.bam.bai | awk '{s+=$3+$4} END {print s}'

#number of mapped reads
samtools SAMPLE.bam.bai | awk '{s+=$3} END {print s}'

Consensus sequence
get consensus sequence (of most frequent bases) based on short reads, mapped against a reference sequence (gene or complete genome)

1) Map short reads against reference gene sequence
# Create bowtie2 database
bowtie2-build rhv_ref_db01.fasta REF_DB

# bowtie2 mapping


bowtie2 -x rhv_ref_db01 -U V338470961_S2_L001_R1_001.trimmed.fastq.gz -S SAMPLE.sam
samtools view -bS SAMPLE.sam SAMPLE.bam


/Users/Kurtisc/Downloads/CURRENT/Virus_Genome_Mapping_Pipeline/Virus_Genome_Mapping_Pipeline/virus_ref_db/V338470961_S2_L001_R1_001.bam
/Users/Kurtisc/Downloads/bbmap/bbmap.sh in=V338470961_S2_L001_R1_001.trimmed.fastq.gz outm=V338470961_S2_L001_R1_001.bam ref=rhv_ref_db01.fasta local=true




samtools sort -o V338470881_S9_L001_R1_001.sorted.bam -O bam -T  V338470881_S9_L001_R1_001.sam




bowtie2 -x REF_DB -U V338470961_S2_L001_R1_001.trimmed.fastq.gz --no-unal -S SAMPLE.sam

bowtie2 -p 10 --local -x REF_DB -U V338470961_S2_L001_R1_001.trimmed.fastq.gz --very-sensitive-local 2> SAMPLE.bowtie2.log -S SAMPLE.sam

bowtie2 -p 10 --local -x REF_DB -U V338470961_S2_L001_R1_001.trimmed.fastq.gz 2> SAMPLE.bowtie2.log -S SAMPLE.sam
 
        
samtools index SAMPLE.bam

samtools mpileup SAMPLE.bam | awk -v X="${MIN_COVERAGE_DEPTH}" '$4>=X' | wc -l
        
        
# samtools:  sort .sam file and convert to .bam file

samtools view -bS V338470961_S2_L002_R1_001.sam | samtools sort - -o SAMPLE.bam

2) Get consensus sequence from .bam file
# Get consensus fastq file
bcftools mpileup -uf V338470961_S2_L002_R1_001_mapped_ref_genome.fasta SAMPLE.bam | bcftools call -c | vcfutils.pl vcf2fq > SAMPLE_cns.fastq

seqtk subseq in.fq list.txt > out.fq


  # vcfutils.pl is part of bcftools

# Convert .fastq to .fasta and set bases of quality lower than 20 to N
seqtk seq -aQ64 -q20 -n N SAMPLE_cns.fastq > SAMPLE_cns.fasta





GENOME MAPPING TO CONSENSUS WORKFLOW

# mapping
V338470961_S2_L002_R1_001.sam

# fasta ref genome mapped to 
V338470961_S2_L002_R1_001_mapped_ref_genome.fasta

# sam to bam
cd

# Sort sam
samtools sort V338470961_S2_L002_R1_001.sam


# Index bam
samtools index V338470961_S2_L002_R1_001.bam

# Sort bam
samtools sort V338470961_S2_L002_R1_001.bam


# call variants
bcftools mpileup -Ou -f V338470961_S2_L002_R1_001_mapped_ref_genome.fasta V338470961_S2_L002_R1_001.sorted.bam | bcftools call -mv -Oz -o calls.vcf.gz --ploidy

# Index vcf
bcftools index calls.vcf.gz

# normalize indels
bcftools norm -f V338470961_S2_L002_R1_001_mapped_ref_genome.fasta calls.vcf.gz -Ob -o calls.norm.bcf

# filter adjacent indels within 5bp
bcftools filter --IndelGap 5 calls.norm.bcf -Ob -o calls.norm.flt-indels.bcf

# consensus sequence
cat reference.fa | bcftools consensus calls.vcf.gz > consensus.fa






# SAM to consensus FASTA code golf, inspired by http://lab.loman.net/2015/07/28/calling-haploid-consensus-sequence/

# Starting with a SAM:
samtools view -bS seqs.sam | samtools sort - seqs # Generate and sort BAM
samtools index seqs.bam # Index BAM

# Starting with an indexed BAM:
samtools mpileup -ud 1000 -f seqs_ref.fasta seqs.bam | bcftools call -c | vcfutils.pl vcf2fq | seqtk seq -a - > seqs.consensus.fa # Generate pileup, call variants, convert to fq, convert to fa

# Who can do better? The bar is set low...




samtools view -bS V338470961_S2_L002_R1_001.sam | samtools sort - seqs












